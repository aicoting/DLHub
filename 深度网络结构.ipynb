{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a78699fa",
   "metadata": {},
   "source": [
    "## 1.卷积神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6656056c",
   "metadata": {},
   "source": [
    "### 卷积"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6861b963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'sharp')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imread\n",
    "# %matplotlib inline\n",
    "\n",
    "I_xray = imread('data/xray_image.png')[::4,::4]\n",
    "# make sure to copy, otherwise they reference the same memory (same variable)\n",
    "I_xray_sharp = I_xray.copy()\n",
    "\n",
    "im_size = I_xray.shape\n",
    "\n",
    "#### your code starts ####\n",
    "## step 1. create the kernel matrix\n",
    "# kernel = np.array([[-1, -1, -1],\n",
    "#                    [-1, 7, -1],\n",
    "#                    [-1, -1, -1]])\n",
    "kernel = np.array([[0, -1, 0],\n",
    "                   [-1, 5, -1],\n",
    "                   [0, -1, 0]])\n",
    "## step 2 & 3. modify the median filter code for filtering\n",
    "# 卷积核大小\n",
    "psz_h = 1\n",
    "\n",
    "# 使用块级操作进行锐化滤波\n",
    "for row in range(psz_h, im_size[0] - psz_h):\n",
    "    for col in range(psz_h, im_size[1] - psz_h):\n",
    "        # 提取 3x3 的图像块\n",
    "        patch = I_xray[row - psz_h: row + psz_h + 1, col - psz_h: col + psz_h + 1]\n",
    "        # 进行卷积操作：元素乘积并求和\n",
    "        I_xray_sharp[row, col] = np.sum(patch * kernel)\n",
    "\n",
    "# 将值限制在 0 到 255 之间，防止溢出\n",
    "I_xray_sharp = np.clip(I_xray_sharp, 0, 255).astype(np.uint8)\n",
    "\n",
    "#### your code starts ####\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(I_xray, cmap='gray');plt.axis('off');plt.title('original')\n",
    "plt.subplot(122)\n",
    "plt.imshow(I_xray_sharp, cmap='gray');plt.axis('off');plt.title('sharp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e3b564",
   "metadata": {},
   "source": [
    "### 池化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9681e6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入特征图：\n",
      "tensor([[1., 3., 2., 4.],\n",
      "        [5., 6., 7., 8.],\n",
      "        [2., 4., 1., 3.],\n",
      "        [0., 1., 2., 4.]])\n",
      "\n",
      "最大池化结果：\n",
      "tensor([[6., 8.],\n",
      "        [4., 4.]])\n",
      "\n",
      "平均池化结果：\n",
      "tensor([[3.7500, 5.2500],\n",
      "        [1.7500, 2.5000]])\n",
      "\n",
      "全局最大池化结果：\n",
      "tensor([[8.]])\n",
      "\n",
      "全局平均池化结果：\n",
      "tensor([[3.3125]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 构造 1x1x4x4 特征图\n",
    "feature_map = torch.tensor([[[[1, 3, 2, 4],\n",
    "                              [5, 6, 7, 8],\n",
    "                              [2, 4, 1, 3],\n",
    "                              [0, 1, 2, 4]]]], dtype=torch.float32)\n",
    "\n",
    "print(\"输入特征图：\")\n",
    "print(feature_map[0,0])\n",
    "\n",
    "# 1. 最大池化（2x2，stride=2）\n",
    "max_pooled = F.max_pool2d(feature_map, kernel_size=2, stride=2)\n",
    "print(\"\\n最大池化结果：\")\n",
    "print(max_pooled[0,0])\n",
    "\n",
    "# 2. 平均池化（2x2，stride=2）\n",
    "avg_pooled = F.avg_pool2d(feature_map, kernel_size=2, stride=2)\n",
    "print(\"\\n平均池化结果：\")\n",
    "print(avg_pooled[0,0])\n",
    "\n",
    "# 3. 全局最大池化（整个特征图）\n",
    "global_max = F.adaptive_max_pool2d(feature_map, output_size=1)\n",
    "print(\"\\n全局最大池化结果：\")\n",
    "print(global_max[0,0])\n",
    "\n",
    "# 4. 全局平均池化（整个特征图）\n",
    "global_avg = F.adaptive_avg_pool2d(feature_map, output_size=1)\n",
    "print(\"\\n全局平均池化结果：\")\n",
    "print(global_avg[0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09529d2",
   "metadata": {},
   "source": [
    "## 2.循环神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b484ce12",
   "metadata": {},
   "source": [
    "### 标准RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "546a8c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 2])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 定义一个标准 RNN 模型\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        # RNN 层\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        # 全连接输出层\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 初始化隐藏状态 h0 (batch_size, num_layers, hidden_size)\n",
    "        h0 = torch.zeros(1, x.size(0), self.hidden_size)\n",
    "        # RNN 前向传播\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        # 取最后时间步的隐藏状态作为输出\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "# 示例：输入大小=10，隐藏层=20，输出大小=2\n",
    "model = RNNModel(input_size=10, hidden_size=20, output_size=2)\n",
    "x = torch.randn(5, 7, 10)  # (batch=5, seq_len=7, input_size=10)\n",
    "y = model(x)\n",
    "print(y.shape)  # 输出: (5, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b32aeb7",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3fc3be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 2])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 定义 LSTM 模型\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        # LSTM 层\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        # 全连接输出层\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 初始化隐藏状态 (h0, c0)\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
    "        # LSTM 前向传播\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        # 取最后时间步的输出\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "# 示例：输入大小=10，隐藏层=20，输出大小=2\n",
    "model = LSTMModel(input_size=10, hidden_size=20, output_size=2)\n",
    "x = torch.randn(5, 7, 10)  # (batch=5, seq_len=7, input_size=10)\n",
    "y = model(x)\n",
    "print(y.shape)  # 输出: (5, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487e5659",
   "metadata": {},
   "source": [
    "### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a536931e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 2])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 定义 GRU 模型\n",
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        # GRU 层\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        # 全连接输出层\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 初始化隐藏状态 h0\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
    "        # GRU 前向传播\n",
    "        out, _ = self.gru(x, h0)\n",
    "        # 取最后时间步的输出\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "# 示例：输入大小=10，隐藏层=20，输出大小=2\n",
    "model = GRUModel(input_size=10, hidden_size=20, output_size=2)\n",
    "x = torch.randn(5, 7, 10)  # (batch=5, seq_len=7, input_size=10)\n",
    "y = model(x)\n",
    "print(y.shape)  # 输出: (5, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8812885e",
   "metadata": {},
   "source": [
    "### Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62a0496e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 8, 10])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 编码器\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs, (hidden, cell) = self.lstm(x)\n",
    "        return hidden, cell  # 返回最后的隐藏状态和记忆单元\n",
    "\n",
    "# 解码器\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_size, hidden_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.lstm = nn.LSTM(output_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, hidden, cell):\n",
    "        outputs, (hidden, cell) = self.lstm(x, (hidden, cell))\n",
    "        predictions = self.fc(outputs)\n",
    "        return predictions, hidden, cell\n",
    "\n",
    "# Seq2Seq 模型\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "        hidden, cell = self.encoder(src)\n",
    "        outputs = []\n",
    "        input = trg[:, 0:1, :]  # 第一个输入 (起始符号)\n",
    "\n",
    "        for t in range(1, trg.size(1)):\n",
    "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
    "            outputs.append(output)\n",
    "            # 是否使用教师强制\n",
    "            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n",
    "            input = trg[:, t:t+1, :] if teacher_force else output\n",
    "        return torch.cat(outputs, dim=1)\n",
    "\n",
    "# 示例\n",
    "encoder = Encoder(input_size=10, hidden_size=20)\n",
    "decoder = Decoder(output_size=10, hidden_size=20)\n",
    "model = Seq2Seq(encoder, decoder)\n",
    "\n",
    "src = torch.randn(5, 7, 10)  # (batch=5, seq_len=7, input_size=10)\n",
    "trg = torch.randn(5, 9, 10)  # (batch=5, seq_len=9, output_size=10)\n",
    "out = model(src, trg)\n",
    "print(out.shape)  # 输出: (5, 8, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8862ab",
   "metadata": {},
   "source": [
    "### Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4107e5de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 20])\n",
      "torch.Size([5, 7])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(Attention, self).__init__()\n",
    "        self.attn = nn.Linear(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        # hidden: (batch, hidden_size)\n",
    "        # encoder_outputs: (batch, seq_len, hidden_size)\n",
    "        # 计算对齐分数\n",
    "        scores = torch.bmm(encoder_outputs, hidden.unsqueeze(2)).squeeze(2)  # (batch, seq_len)\n",
    "        attn_weights = F.softmax(scores, dim=1)  # 注意力权重\n",
    "        # 计算上下文向量\n",
    "        context = torch.bmm(attn_weights.unsqueeze(1), encoder_outputs)  # (batch, 1, hidden_size)\n",
    "        context = context.squeeze(1)  # (batch, hidden_size)\n",
    "        return context, attn_weights\n",
    "\n",
    "# 示例\n",
    "batch_size, seq_len, hidden_size = 5, 7, 20\n",
    "encoder_outputs = torch.randn(batch_size, seq_len, hidden_size)\n",
    "hidden = torch.randn(batch_size, hidden_size)\n",
    "\n",
    "attn = Attention(hidden_size)\n",
    "context, weights = attn(hidden, encoder_outputs)\n",
    "print(context.shape)  # (5, 20)\n",
    "print(weights.shape)  # (5, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9854b132",
   "metadata": {},
   "source": [
    "## 3.Transformer与注意力机制"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a870e6",
   "metadata": {},
   "source": [
    "### Self Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8eca00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 7, 32])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, embed_size, heads):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.heads = heads\n",
    "        self.head_dim = embed_size // heads\n",
    "\n",
    "        assert embed_size % heads == 0, \"Embedding size must be divisible by heads\"\n",
    "\n",
    "        self.W_Q = nn.Linear(embed_size, embed_size, bias=False)\n",
    "        self.W_K = nn.Linear(embed_size, embed_size, bias=False)\n",
    "        self.W_V = nn.Linear(embed_size, embed_size, bias=False)\n",
    "        self.fc_out = nn.Linear(embed_size, embed_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        N, seq_len, embed_size = x.shape\n",
    "        Q = self.W_Q(x).view(N, seq_len, self.heads, self.head_dim)\n",
    "        K = self.W_K(x).view(N, seq_len, self.heads, self.head_dim)\n",
    "        V = self.W_V(x).view(N, seq_len, self.heads, self.head_dim)\n",
    "\n",
    "        Q, K, V = Q.transpose(1,2), K.transpose(1,2), V.transpose(1,2)  # (N, heads, seq_len, head_dim)\n",
    "\n",
    "        energy = torch.matmul(Q, K.transpose(-2, -1)) / (self.head_dim ** 0.5)  # (N, heads, seq_len, seq_len)\n",
    "        attention = F.softmax(energy, dim=-1)\n",
    "\n",
    "        out = torch.matmul(attention, V)  # (N, heads, seq_len, head_dim)\n",
    "        out = out.transpose(1,2).contiguous().view(N, seq_len, embed_size)\n",
    "        return self.fc_out(out)\n",
    "\n",
    "# 示例\n",
    "x = torch.randn(5, 7, 32)  # (batch=5, seq_len=7, embed_size=32)\n",
    "self_attn = SelfAttention(embed_size=32, heads=4)\n",
    "out = self_attn(x)\n",
    "print(out.shape)  # (5, 7, 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b6c07a",
   "metadata": {},
   "source": [
    "### Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0928abef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "# ----------------------\n",
    "# 1. Multi-Head Self Attention\n",
    "# ----------------------\n",
    "class MultiHeadSelfAttention(nn.Module):\n",
    "    def __init__(self, hidden_dim, num_heads):\n",
    "        super().__init__()\n",
    "        assert hidden_dim % num_heads == 0, \"hidden_dim 必须能被 num_heads 整除\"\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = hidden_dim // num_heads\n",
    "        \n",
    "        self.query = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.key   = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.value = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.out   = nn.Linear(hidden_dim, hidden_dim)\n",
    "    \n",
    "    def forward(self, x, mask=None):\n",
    "        B, L, D = x.size()  # batch_size, seq_len, hidden_dim\n",
    "        \n",
    "        # 线性映射\n",
    "        Q = self.query(x).view(B, L, self.num_heads, self.head_dim).transpose(1, 2)  # [B, heads, L, head_dim]\n",
    "        K = self.key(x).view(B, L, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        V = self.value(x).view(B, L, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        \n",
    "        # Scaled Dot-Product Attention\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.head_dim)  # [B, heads, L, L]\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, -1e9)\n",
    "        attn = torch.softmax(scores, dim=-1)\n",
    "        \n",
    "        out = torch.matmul(attn, V)  # [B, heads, L, head_dim]\n",
    "        out = out.transpose(1, 2).contiguous().view(B, L, D)  # [B, L, hidden_dim]\n",
    "        return self.out(out)\n",
    "\n",
    "# ----------------------\n",
    "# 2. Transformer Encoder Block\n",
    "# ----------------------\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, hidden_dim, num_heads, ff_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.attn = MultiHeadSelfAttention(hidden_dim, num_heads)\n",
    "        self.norm1 = nn.LayerNorm(hidden_dim)\n",
    "        self.norm2 = nn.LayerNorm(hidden_dim)\n",
    "        \n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, ff_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(ff_dim, hidden_dim)\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x, mask=None):\n",
    "        # Self-Attention + 残差\n",
    "        attn_out = self.attn(x, mask)\n",
    "        x = self.norm1(x + self.dropout(attn_out))\n",
    "        \n",
    "        # Feed Forward + 残差\n",
    "        ff_out = self.ff(x)\n",
    "        x = self.norm2(x + self.dropout(ff_out))\n",
    "        return x\n",
    "\n",
    "# ----------------------\n",
    "# 3. BERT Embeddings\n",
    "# ----------------------\n",
    "class BERTEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_dim, max_len=512, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.token_emb = nn.Embedding(vocab_size, hidden_dim)\n",
    "        self.pos_emb   = nn.Embedding(max_len, hidden_dim)\n",
    "        self.seg_emb   = nn.Embedding(2, hidden_dim)  # segment A / B\n",
    "        self.norm = nn.LayerNorm(hidden_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, input_ids, segment_ids):\n",
    "        B, L = input_ids.size()\n",
    "        pos_ids = torch.arange(L, device=input_ids.device).unsqueeze(0).expand(B, L)\n",
    "        \n",
    "        x = self.token_emb(input_ids) + self.pos_emb(pos_ids) + self.seg_emb(segment_ids)\n",
    "        return self.dropout(self.norm(x))\n",
    "\n",
    "# ----------------------\n",
    "# 4. BERT Model\n",
    "# ----------------------\n",
    "class BERT(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_dim=768, num_heads=12, ff_dim=3072, num_layers=12, max_len=512):\n",
    "        super().__init__()\n",
    "        self.embedding = BERTEmbedding(vocab_size, hidden_dim, max_len)\n",
    "        self.layers = nn.ModuleList([\n",
    "            TransformerBlock(hidden_dim, num_heads, ff_dim) for _ in range(num_layers)\n",
    "        ])\n",
    "        self.cls_head = nn.Linear(hidden_dim, vocab_size)  # 用于 MLM\n",
    "    \n",
    "    def forward(self, input_ids, segment_ids, mask=None):\n",
    "        x = self.embedding(input_ids, segment_ids)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "        logits = self.cls_head(x)  # MLM 任务输出\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1b91216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 10, 30522])\n"
     ]
    }
   ],
   "source": [
    "# 模拟输入\n",
    "vocab_size = 30522  # 与 BERT 一致\n",
    "model = BERT(vocab_size)\n",
    "\n",
    "input_ids = torch.randint(0, vocab_size, (2, 10))  # batch_size=2, seq_len=10\n",
    "segment_ids = torch.zeros_like(input_ids)  # 全部属于句子 A\n",
    "\n",
    "logits = model(input_ids, segment_ids)\n",
    "print(logits.shape)  # [2, 10, vocab_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197feaea",
   "metadata": {},
   "source": [
    "### GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7ae1653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 10, 5000])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "class GPTBlock(nn.Module):\n",
    "    def __init__(self, hidden_dim, num_heads, ff_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.attn = nn.MultiheadAttention(hidden_dim, num_heads, dropout=dropout, batch_first=True)\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, ff_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(ff_dim, hidden_dim)\n",
    "        )\n",
    "        self.norm1 = nn.LayerNorm(hidden_dim)\n",
    "        self.norm2 = nn.LayerNorm(hidden_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x, mask=None):\n",
    "        attn_out, _ = self.attn(x, x, x, attn_mask=mask)\n",
    "        x = self.norm1(x + self.dropout(attn_out))\n",
    "        ff_out = self.ff(x)\n",
    "        x = self.norm2(x + self.dropout(ff_out))\n",
    "        return x\n",
    "\n",
    "class GPT(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_dim=256, num_heads=4, ff_dim=512, num_layers=4, max_len=128):\n",
    "        super().__init__()\n",
    "        self.token_emb = nn.Embedding(vocab_size, hidden_dim)\n",
    "        self.pos_emb = nn.Embedding(max_len, hidden_dim)\n",
    "        self.layers = nn.ModuleList([GPTBlock(hidden_dim, num_heads, ff_dim) for _ in range(num_layers)])\n",
    "        self.ln_f = nn.LayerNorm(hidden_dim)\n",
    "        self.head = nn.Linear(hidden_dim, vocab_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        B, L = x.size()\n",
    "        pos = torch.arange(L, device=x.device).unsqueeze(0).expand(B, L)\n",
    "        x = self.token_emb(x) + self.pos_emb(pos)\n",
    "        \n",
    "        # Mask：防止看到未来的 token\n",
    "        mask = torch.triu(torch.ones(L, L, device=x.device), diagonal=1).bool()\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "        x = self.ln_f(x)\n",
    "        return self.head(x)\n",
    "\n",
    "# 测试\n",
    "vocab_size = 5000\n",
    "model = GPT(vocab_size)\n",
    "input_ids = torch.randint(0, vocab_size, (2, 10))\n",
    "logits = model(input_ids)\n",
    "print(logits.shape)  # [2, 10, vocab_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97a0ec8",
   "metadata": {},
   "source": [
    "### Vision Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f41c1248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1000])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class PatchEmbedding(nn.Module):\n",
    "    def __init__(self, img_size=224, patch_size=16, in_ch=3, emb_dim=768):\n",
    "        super().__init__()\n",
    "        self.patch_embed = nn.Conv2d(in_ch, emb_dim, kernel_size=patch_size, stride=patch_size)\n",
    "        self.num_patches = (img_size // patch_size) ** 2\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.patch_embed(x)  # [B, emb_dim, H/patch, W/patch]\n",
    "        x = x.flatten(2).transpose(1, 2)  # [B, num_patches, emb_dim]\n",
    "        return x\n",
    "\n",
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, emb_dim=768, num_heads=12, ff_dim=3072, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.attn = nn.MultiheadAttention(emb_dim, num_heads, dropout=dropout, batch_first=True)\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(emb_dim, ff_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(ff_dim, emb_dim)\n",
    "        )\n",
    "        self.norm1 = nn.LayerNorm(emb_dim)\n",
    "        self.norm2 = nn.LayerNorm(emb_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        attn_out, _ = self.attn(x, x, x)\n",
    "        x = self.norm1(x + self.dropout(attn_out))\n",
    "        ff_out = self.ff(x)\n",
    "        x = self.norm2(x + self.dropout(ff_out))\n",
    "        return x\n",
    "\n",
    "class VisionTransformer(nn.Module):\n",
    "    def __init__(self, img_size=224, patch_size=16, in_ch=3, emb_dim=768, num_heads=12, ff_dim=3072, num_layers=12, num_classes=1000):\n",
    "        super().__init__()\n",
    "        self.patch_embedding = PatchEmbedding(img_size, patch_size, in_ch, emb_dim)\n",
    "        self.cls_token = nn.Parameter(torch.zeros(1, 1, emb_dim))\n",
    "        self.pos_emb = nn.Parameter(torch.zeros(1, 1 + self.patch_embedding.num_patches, emb_dim))\n",
    "        \n",
    "        self.layers = nn.ModuleList([TransformerEncoder(emb_dim, num_heads, ff_dim) for _ in range(num_layers)])\n",
    "        self.norm = nn.LayerNorm(emb_dim)\n",
    "        self.head = nn.Linear(emb_dim, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        B = x.size(0)\n",
    "        x = self.patch_embedding(x)\n",
    "        cls_tokens = self.cls_token.expand(B, -1, -1)\n",
    "        x = torch.cat((cls_tokens, x), dim=1) + self.pos_emb\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        \n",
    "        x = self.norm(x)\n",
    "        cls_out = x[:, 0]  # [CLS] Token\n",
    "        return self.head(cls_out)\n",
    "\n",
    "# 测试\n",
    "model = VisionTransformer()\n",
    "dummy = torch.randn(2, 3, 224, 224)\n",
    "logits = model(dummy)\n",
    "print(logits.shape)  # [2, 1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54fb2be",
   "metadata": {},
   "source": [
    "## 4.生成与表示模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03cb71e7",
   "metadata": {},
   "source": [
    "### AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcc8bb46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstruction Loss: 0.0845540389418602\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# 定义自编码器\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim=784, hidden_dim=128, latent_dim=32):\n",
    "        super().__init__()\n",
    "        # 编码器\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, latent_dim)\n",
    "        )\n",
    "        # 解码器\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, input_dim),\n",
    "            nn.Sigmoid()  # 输出归一化到 [0,1]\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        out = self.decoder(z)\n",
    "        return out\n",
    "\n",
    "# 模拟训练\n",
    "model = Autoencoder()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "x = torch.rand(16, 784)  # batch_size=16, MNIST 展平输入\n",
    "output = model(x)\n",
    "loss = criterion(output, x)\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "print(\"Reconstruction Loss:\", loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4189d039",
   "metadata": {},
   "source": [
    "### VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e2cf828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAE Loss: 8795.5419921875\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_dim=784, hidden_dim=400, latent_dim=20):\n",
    "        super().__init__()\n",
    "        # 编码器\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc_mu = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(hidden_dim, latent_dim)\n",
    "        # 解码器\n",
    "        self.fc2 = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, input_dim)\n",
    "    \n",
    "    def encode(self, x):\n",
    "        h = torch.relu(self.fc1(x))\n",
    "        return self.fc_mu(h), self.fc_logvar(h)\n",
    "    \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "    \n",
    "    def decode(self, z):\n",
    "        h = torch.relu(self.fc2(z))\n",
    "        return torch.sigmoid(self.fc3(h))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    BCE = nn.functional.binary_cross_entropy(recon_x, x, reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return BCE + KLD\n",
    "\n",
    "# 测试\n",
    "model = VAE()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "x = torch.rand(16, 784)  # batch_size=16\n",
    "recon_x, mu, logvar = model(x)\n",
    "loss = loss_function(recon_x, x, mu, logvar)\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "print(\"VAE Loss:\", loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b49c01",
   "metadata": {},
   "source": [
    "### GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "728ef539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss_D: 1.405836582183838 Loss_G: 0.6890441179275513\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# 生成器\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, noise_dim=100, img_dim=784):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(noise_dim, 256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(512, img_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    def forward(self, z):\n",
    "        return self.model(z)\n",
    "\n",
    "# 判别器\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_dim=784):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(img_dim, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# 初始化\n",
    "noise_dim = 100\n",
    "G = Generator(noise_dim)\n",
    "D = Discriminator()\n",
    "criterion = nn.BCELoss()\n",
    "optim_G = optim.Adam(G.parameters(), lr=0.0002)\n",
    "optim_D = optim.Adam(D.parameters(), lr=0.0002)\n",
    "\n",
    "# 模拟训练\n",
    "real_data = torch.rand(16, 784) * 2 - 1  # [-1, 1] 区间\n",
    "z = torch.randn(16, noise_dim)\n",
    "fake_data = G(z)\n",
    "\n",
    "# 判别器训练\n",
    "real_labels = torch.ones(16, 1)\n",
    "fake_labels = torch.zeros(16, 1)\n",
    "loss_real = criterion(D(real_data), real_labels)\n",
    "loss_fake = criterion(D(fake_data.detach()), fake_labels)\n",
    "loss_D = loss_real + loss_fake\n",
    "optim_D.zero_grad()\n",
    "loss_D.backward()\n",
    "optim_D.step()\n",
    "\n",
    "# 生成器训练\n",
    "loss_G = criterion(D(fake_data), real_labels)\n",
    "optim_G.zero_grad()\n",
    "loss_G.backward()\n",
    "optim_G.step()\n",
    "\n",
    "print(\"Loss_D:\", loss_D.item(), \"Loss_G:\", loss_G.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da20342f",
   "metadata": {},
   "source": [
    "### Diffusion model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82b59a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diffusion training loss: 1.0335407257080078\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# 简化版 U-Net 去噪器\n",
    "class SimpleDenoiser(nn.Module):\n",
    "    def __init__(self, dim=128):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(784 + 1, dim),  # 输入 + 时间步\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(dim, 784)\n",
    "        )\n",
    "    def forward(self, x, t):\n",
    "        t_embed = t.float().unsqueeze(1) / 1000  # 简单时间嵌入\n",
    "        return self.net(torch.cat([x, t_embed], dim=1))\n",
    "\n",
    "# 训练过程\n",
    "model = SimpleDenoiser()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "x0 = torch.rand(16, 784)  # MNIST 展平\n",
    "t = torch.randint(1, 1000, (16,))  # 时间步\n",
    "noise = torch.randn_like(x0)\n",
    "\n",
    "alpha_bar = torch.exp(-0.001 * t.float()).unsqueeze(1)\n",
    "xt = torch.sqrt(alpha_bar) * x0 + torch.sqrt(1 - alpha_bar) * noise\n",
    "\n",
    "pred_noise = model(xt, t)\n",
    "loss = nn.MSELoss()(pred_noise, noise)\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "print(\"Diffusion training loss:\", loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a5eb5d",
   "metadata": {},
   "source": [
    "### DDPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bba92e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DDPM Loss: 1.0429922342300415\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# 简单噪声预测网络\n",
    "class NoisePredictor(nn.Module):\n",
    "    def __init__(self, dim=128):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(784 + 1, dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(dim, 784)\n",
    "        )\n",
    "    def forward(self, x, t):\n",
    "        t_embed = t.float().unsqueeze(1) / 1000\n",
    "        return self.net(torch.cat([x, t_embed], dim=1))\n",
    "\n",
    "# 初始化\n",
    "model = NoisePredictor()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# 假设有 batch 数据\n",
    "x0 = torch.rand(16, 784)\n",
    "t = torch.randint(1, 1000, (16,))\n",
    "noise = torch.randn_like(x0)\n",
    "\n",
    "alpha_bar = torch.exp(-0.001 * t.float()).unsqueeze(1)\n",
    "xt = torch.sqrt(alpha_bar) * x0 + torch.sqrt(1 - alpha_bar) * noise\n",
    "\n",
    "# 预测噪声并计算损失\n",
    "pred_noise = model(xt, t)\n",
    "loss = nn.MSELoss()(pred_noise, noise)\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "print(\"DDPM Loss:\", loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e2c618",
   "metadata": {},
   "source": [
    "### Stable Diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d696e3b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred noise: tensor([[-0.2995, -0.2235, -0.1514,  0.1756]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 简化的 U-Net 去噪模块\n",
    "class UNetDenoiser(nn.Module):\n",
    "    def __init__(self, latent_dim=4, cond_dim=768, hidden_dim=128):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(latent_dim + cond_dim + 1, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, latent_dim)\n",
    "    def forward(self, z, t, cond):\n",
    "        t_embed = t.float().unsqueeze(1) / 1000\n",
    "        x = torch.cat([z, cond, t_embed], dim=1)\n",
    "        return self.fc2(torch.relu(self.fc1(x)))\n",
    "\n",
    "# 模拟采样\n",
    "z = torch.randn(1, 4)              # 潜在噪声\n",
    "cond = torch.randn(1, 768)         # 文本条件嵌入\n",
    "t = torch.randint(1, 1000, (1,))   # 时间步\n",
    "model = UNetDenoiser()\n",
    "\n",
    "pred_noise = model(z, t, cond)     # 预测噪声\n",
    "print(\"Pred noise:\", pred_noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54324cd2",
   "metadata": {},
   "source": [
    "## 5.图神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ea2d3b",
   "metadata": {},
   "source": [
    "### GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d7279f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "节点表示： tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GCNLayer(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(in_dim, out_dim)\n",
    "\n",
    "    def forward(self, X, A_hat):\n",
    "        # A_hat: 归一化后的邻接矩阵 (D^-1/2 (A+I) D^-1/2)\n",
    "        out = torch.mm(A_hat, X)  # 聚合邻居信息\n",
    "        out = self.linear(out)    # 线性变换\n",
    "        return F.relu(out)        # 非线性激活\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.gcn1 = GCNLayer(in_dim, hidden_dim)\n",
    "        self.gcn2 = GCNLayer(hidden_dim, out_dim)\n",
    "\n",
    "    def forward(self, X, A_hat):\n",
    "        h = self.gcn1(X, A_hat)\n",
    "        h = self.gcn2(h, A_hat)\n",
    "        return h  # 输出节点表示\n",
    "\n",
    "# 测试\n",
    "N, d = 4, 5\n",
    "X = torch.rand(N, d)                 # 节点特征\n",
    "A = torch.tensor([[1,1,0,0],\n",
    "                  [1,1,1,0],\n",
    "                  [0,1,1,1],\n",
    "                  [0,0,1,1]], dtype=torch.float32)  # 邻接矩阵+自环\n",
    "\n",
    "D = torch.diag(torch.pow(A.sum(1), -0.5))\n",
    "A_hat = D @ A @ D  # 归一化邻接矩阵\n",
    "\n",
    "model = GCN(in_dim=d, hidden_dim=8, out_dim=2)\n",
    "out = model(X, A_hat)\n",
    "print(\"节点表示：\", out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70660c69",
   "metadata": {},
   "source": [
    "### GAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e879b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "节点表示： tensor([[-0.0585, -0.1497],\n",
      "        [ 0.0352, -0.2149],\n",
      "        [-0.0566, -0.1379],\n",
      "        [-0.0218, -0.1714]], grad_fn=<EluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GATLayer(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, alpha=0.2):\n",
    "        super().__init__()\n",
    "        self.W = nn.Linear(in_dim, out_dim, bias=False)\n",
    "        self.a = nn.Linear(2*out_dim, 1, bias=False)\n",
    "        self.leakyrelu = nn.LeakyReLU(alpha)\n",
    "\n",
    "    def forward(self, X, adj):\n",
    "        H = self.W(X)  # 节点线性变换\n",
    "        N = H.size(0)\n",
    "\n",
    "        # 注意力系数\n",
    "        a_input = torch.cat([H.repeat(1, N).view(N*N, -1),\n",
    "                             H.repeat(N, 1)], dim=1).view(N, N, -1)\n",
    "        e = self.leakyrelu(self.a(a_input).squeeze(2))\n",
    "\n",
    "        # 只在邻居间计算注意力\n",
    "        zero_vec = -9e15*torch.ones_like(e)\n",
    "        attention = torch.where(adj > 0, e, zero_vec)\n",
    "        attention = F.softmax(attention, dim=1)\n",
    "\n",
    "        # 聚合邻居特征\n",
    "        h_prime = torch.matmul(attention, H)\n",
    "        return F.elu(h_prime)\n",
    "\n",
    "# 测试\n",
    "N, d = 4, 5\n",
    "X = torch.rand(N, d)\n",
    "adj = torch.tensor([[1,1,0,0],\n",
    "                    [1,1,1,0],\n",
    "                    [0,1,1,1],\n",
    "                    [0,0,1,1]], dtype=torch.float32)\n",
    "\n",
    "gat = GATLayer(in_dim=d, out_dim=2)\n",
    "out = gat(X, adj)\n",
    "print(\"节点表示：\", out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wlt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
